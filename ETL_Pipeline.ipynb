{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78938db2-cd88-43c7-838d-b0b5f585ff41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import required libraries and load environment variables\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Environment variables loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d5068fd-24ac-4733-b6a3-ad0e22cc384a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake environment setup:\n",
      "Account: True | User: True | Password: True | Warehouse: True\n",
      "Database: True | Schema: True\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Read Snowflake credentials from environment variables\n",
    "\n",
    "account = os.getenv(\"SNOWFLAKE_ACCOUNT\")\n",
    "user = os.getenv(\"SNOWFLAKE_USER\")\n",
    "password  = os.getenv(\"SNOWFLAKE_PASSWORD\")\n",
    "warehouse = os.getenv(\"SNOWFLAKE_WAREHOUSE\")\n",
    "database = os.getenv(\"SNOWFLAKE_DATABASE\")\n",
    "schema = os.getenv(\"SNOWFLAKE_SCHEMA\")\n",
    "\n",
    "# Print summary\n",
    "print(\"Snowflake environment setup:\")\n",
    "print(f\"Account: {bool(account)} | User: {bool(user)} | Password: {bool(password)} | Warehouse: {bool(warehouse)}\")\n",
    "print(f\"Database: {bool(database)} | Schema: {bool(schema)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "72b2e8f6-16c2-4faa-96f0-0c08e63f5e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Snowflake.\n",
      "Environment Details:\n",
      "Warehouse : COMPUTE_WH\n",
      "Database  : ETL_PROJECT_DB\n",
      "Schema    : ETL_PROJECT_SCHEMA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Establish a secure connection to Snowflake using the credentials\n",
    "\n",
    "conn = snowflake.connector.connect(\n",
    "    account=account,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    warehouse=warehouse,\n",
    "    database=database,\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "# Create a cursor object to run SQL queries\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Run a test query to confirm Snowflake session context\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT \n",
    "        CURRENT_ACCOUNT(), \n",
    "        CURRENT_USER(), \n",
    "        CURRENT_WAREHOUSE(), \n",
    "        CURRENT_DATABASE(), \n",
    "        CURRENT_SCHEMA();\n",
    "\"\"\")\n",
    "\n",
    "# Retrieve and display session info (non-sensitive)\n",
    "result = cursor.fetchone()\n",
    "\n",
    "print(\"Connected to Snowflake.\")\n",
    "print(\"Environment Details:\")\n",
    "print(f\"Warehouse : {result[2]}\")\n",
    "print(f\"Database  : {result[3]}\")\n",
    "print(f\"Schema    : {result[4]}\")\n",
    "\n",
    "# Always close cursor after execution\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a26b71cf-6360-4d91-b325-f0b90f65c7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV File Loaded Successfully.\n",
      "Shape of DataFrame: (9800, 18)\n",
      "\n",
      "First 5 records:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Ship Mode</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Region</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CA-2017-152156</td>\n",
       "      <td>08/11/2017</td>\n",
       "      <td>11/11/2017</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>42420.0</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-BO-10001798</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Bush Somerset Collection Bookcase</td>\n",
       "      <td>261.9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CA-2017-152156</td>\n",
       "      <td>08/11/2017</td>\n",
       "      <td>11/11/2017</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>42420.0</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-CH-10000454</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Chairs</td>\n",
       "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
       "      <td>731.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CA-2017-138688</td>\n",
       "      <td>12/06/2017</td>\n",
       "      <td>16/06/2017</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>DV-13045</td>\n",
       "      <td>Darrin Van Huff</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>90036.0</td>\n",
       "      <td>West</td>\n",
       "      <td>OFF-LA-10000240</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Self-Adhesive Address Labels for Typewriters b...</td>\n",
       "      <td>14.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>US-2016-108966</td>\n",
       "      <td>11/10/2016</td>\n",
       "      <td>18/10/2016</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>Florida</td>\n",
       "      <td>33311.0</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-TA-10000577</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Tables</td>\n",
       "      <td>Bretford CR4500 Series Slim Rectangular Table</td>\n",
       "      <td>957.5775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>US-2016-108966</td>\n",
       "      <td>11/10/2016</td>\n",
       "      <td>18/10/2016</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>Florida</td>\n",
       "      <td>33311.0</td>\n",
       "      <td>South</td>\n",
       "      <td>OFF-ST-10000760</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Storage</td>\n",
       "      <td>Eldon Fold 'N Roll Cart System</td>\n",
       "      <td>22.3680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row ID        Order ID  Order Date   Ship Date       Ship Mode Customer ID  \\\n",
       "0       1  CA-2017-152156  08/11/2017  11/11/2017    Second Class    CG-12520   \n",
       "1       2  CA-2017-152156  08/11/2017  11/11/2017    Second Class    CG-12520   \n",
       "2       3  CA-2017-138688  12/06/2017  16/06/2017    Second Class    DV-13045   \n",
       "3       4  US-2016-108966  11/10/2016  18/10/2016  Standard Class    SO-20335   \n",
       "4       5  US-2016-108966  11/10/2016  18/10/2016  Standard Class    SO-20335   \n",
       "\n",
       "     Customer Name    Segment        Country             City       State  \\\n",
       "0      Claire Gute   Consumer  United States        Henderson    Kentucky   \n",
       "1      Claire Gute   Consumer  United States        Henderson    Kentucky   \n",
       "2  Darrin Van Huff  Corporate  United States      Los Angeles  California   \n",
       "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale     Florida   \n",
       "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale     Florida   \n",
       "\n",
       "   Postal Code Region       Product ID         Category Sub-Category  \\\n",
       "0      42420.0  South  FUR-BO-10001798        Furniture    Bookcases   \n",
       "1      42420.0  South  FUR-CH-10000454        Furniture       Chairs   \n",
       "2      90036.0   West  OFF-LA-10000240  Office Supplies       Labels   \n",
       "3      33311.0  South  FUR-TA-10000577        Furniture       Tables   \n",
       "4      33311.0  South  OFF-ST-10000760  Office Supplies      Storage   \n",
       "\n",
       "                                        Product Name     Sales  \n",
       "0                  Bush Somerset Collection Bookcase  261.9600  \n",
       "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400  \n",
       "2  Self-Adhesive Address Labels for Typewriters b...   14.6200  \n",
       "3      Bretford CR4500 Series Slim Rectangular Table  957.5775  \n",
       "4                     Eldon Fold 'N Roll Cart System   22.3680  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 4: Extract the CSV data\n",
    "\n",
    "# Load CSV file path from environment variable to avoid hardcoding sensitive paths\n",
    "data_file_path = os.getenv(\"DATA_FILE_PATH\")\n",
    "\n",
    "# Check if the file path exists before attempting to read\n",
    "if not os.path.exists(data_file_path):\n",
    "    raise FileNotFoundError(f\"The CSV file at {data_file_path} was not found.\")\n",
    "\n",
    "# Read the CSV into a DataFrame\n",
    "df = pd.read_csv(data_file_path)\n",
    "\n",
    "# Display basic structure and first few rows\n",
    "print(\"\\nCSV File Loaded Successfully.\")\n",
    "print(\"Shape of DataFrame:\", df.shape)\n",
    "\n",
    "# Displaying the first 5 records for a quick preview\n",
    "print(\"\\nFirst 5 records:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1db96931-b0da-46e1-8832-705de77295eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values (Original Data):\n",
      "Row ID            0\n",
      "Order ID          0\n",
      "Order Date        0\n",
      "Ship Date         0\n",
      "Ship Mode         0\n",
      "Customer ID       0\n",
      "Customer Name     0\n",
      "Segment           0\n",
      "Country           0\n",
      "City              0\n",
      "State             0\n",
      "Postal Code      11\n",
      "Region            0\n",
      "Product ID        0\n",
      "Category          0\n",
      "Sub-Category      0\n",
      "Product Name      0\n",
      "Sales             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values across the dataset\n",
    "print(\"\\nMissing Values (Original Data):\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "85fb9f24-f7da-4bc9-b212-5c21eb5c3adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data cleaned and transformed successfully.\n",
      "New columns added: 'Order_Month', 'Delivery Time (Days)'\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Transform – Initial Cleanup & Feature Engineering\n",
    "\n",
    "# Convert 'Order Date' and 'Ship Date' columns to datetime format\n",
    "df[\"Order Date\"] = pd.to_datetime(df[\"Order Date\"], format=\"%d/%m/%Y\")\n",
    "df[\"Ship Date\"] = pd.to_datetime(df[\"Ship Date\"], format=\"%d/%m/%Y\")\n",
    "\n",
    "# Create new column for Month of Order\n",
    "df[\"Order_Month\"] = df[\"Order Date\"].dt.month\n",
    "\n",
    "# Calculate delivery time in days\n",
    "df[\"Delivery Time (Days)\"] = (df[\"Ship Date\"] - df[\"Order Date\"]).dt.days\n",
    "\n",
    "# Handle missing values in 'Postal Code' by replacing with 0 and converting to integer\n",
    "df[\"Postal Code\"] = df[\"Postal Code\"].fillna(0).astype(int)\n",
    "\n",
    "# Drop duplicate rows if any\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Basic transformation completed\n",
    "print(\"\\nData cleaned and transformed successfully.\")\n",
    "print(\"New columns added: 'Order_Month', 'Delivery Time (Days)'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a70660a-e77c-4e94-b797-0860df6f0592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Ship Mode</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Region</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Order_Month</th>\n",
       "      <th>Delivery Time (Days)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CA-2017-152156</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>42420</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-BO-10001798</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Bush Somerset Collection Bookcase</td>\n",
       "      <td>261.96</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CA-2017-152156</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>42420</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-CH-10000454</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Chairs</td>\n",
       "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
       "      <td>731.94</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CA-2017-138688</td>\n",
       "      <td>2017-06-12</td>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>DV-13045</td>\n",
       "      <td>Darrin Van Huff</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>90036</td>\n",
       "      <td>West</td>\n",
       "      <td>OFF-LA-10000240</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Self-Adhesive Address Labels for Typewriters b...</td>\n",
       "      <td>14.62</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row ID        Order ID Order Date  Ship Date     Ship Mode Customer ID  \\\n",
       "0       1  CA-2017-152156 2017-11-08 2017-11-11  Second Class    CG-12520   \n",
       "1       2  CA-2017-152156 2017-11-08 2017-11-11  Second Class    CG-12520   \n",
       "2       3  CA-2017-138688 2017-06-12 2017-06-16  Second Class    DV-13045   \n",
       "\n",
       "     Customer Name    Segment        Country         City       State  \\\n",
       "0      Claire Gute   Consumer  United States    Henderson    Kentucky   \n",
       "1      Claire Gute   Consumer  United States    Henderson    Kentucky   \n",
       "2  Darrin Van Huff  Corporate  United States  Los Angeles  California   \n",
       "\n",
       "   Postal Code Region       Product ID         Category Sub-Category  \\\n",
       "0        42420  South  FUR-BO-10001798        Furniture    Bookcases   \n",
       "1        42420  South  FUR-CH-10000454        Furniture       Chairs   \n",
       "2        90036   West  OFF-LA-10000240  Office Supplies       Labels   \n",
       "\n",
       "                                        Product Name   Sales  Order_Month  \\\n",
       "0                  Bush Somerset Collection Bookcase  261.96           11   \n",
       "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.94           11   \n",
       "2  Self-Adhesive Address Labels for Typewriters b...   14.62            6   \n",
       "\n",
       "   Delivery Time (Days)  \n",
       "0                     3  \n",
       "1                     3  \n",
       "2                     4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Delivery Time (Days)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-06-12</td>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>2016-10-18</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>2016-10-18</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Order Date  Ship Date  Delivery Time (Days)\n",
       "0 2017-11-08 2017-11-11                     3\n",
       "1 2017-11-08 2017-11-11                     3\n",
       "2 2017-06-12 2017-06-16                     4\n",
       "3 2016-10-11 2016-10-18                     7\n",
       "4 2016-10-11 2016-10-18                     7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Remaining Missing Values in 'Postal Code': 0\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Verify and Validate Transformed Data\n",
    "\n",
    "# Preview the first 3 rows to confirm the correct addition of new columns ('Order_Month', 'Delivery Time (Days)')\n",
    "display(df.head(3))\n",
    "\n",
    "# Verify the transformation of delivery-related columns and ensure 'Delivery Time (Days)' was calculated correctly\n",
    "display(df[[\"Order Date\", \"Ship Date\", \"Delivery Time (Days)\"]].head())\n",
    "\n",
    "# Reconfirm that no missing values remain in the 'Postal Code' column after transformation\n",
    "print(\"\\nRemaining Missing Values in 'Postal Code':\", df[\"Postal Code\"].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5fb7684-c57f-4d22-bfdd-330743029fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (9800, 20)\n",
      "\n",
      "Data Types after Transformation:\n",
      "Row ID                           int64\n",
      "Order ID                        object\n",
      "Order Date              datetime64[ns]\n",
      "Ship Date               datetime64[ns]\n",
      "Ship Mode                       object\n",
      "Customer ID                     object\n",
      "Customer Name                   object\n",
      "Segment                         object\n",
      "Country                         object\n",
      "City                            object\n",
      "State                           object\n",
      "Postal Code                      int32\n",
      "Region                          object\n",
      "Product ID                      object\n",
      "Category                        object\n",
      "Sub-Category                    object\n",
      "Product Name                    object\n",
      "Sales                          float64\n",
      "Order_Month                      int32\n",
      "Delivery Time (Days)             int64\n",
      "dtype: object\n",
      "\n",
      "Remaining Missing Values across all columns:\n",
      "Row ID                  0\n",
      "Order ID                0\n",
      "Order Date              0\n",
      "Ship Date               0\n",
      "Ship Mode               0\n",
      "Customer ID             0\n",
      "Customer Name           0\n",
      "Segment                 0\n",
      "Country                 0\n",
      "City                    0\n",
      "State                   0\n",
      "Postal Code             0\n",
      "Region                  0\n",
      "Product ID              0\n",
      "Category                0\n",
      "Sub-Category            0\n",
      "Product Name            0\n",
      "Sales                   0\n",
      "Order_Month             0\n",
      "Delivery Time (Days)    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Final Data Validation\n",
    "\n",
    "# Display final shape (rows, columns)\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "\n",
    "# Display final data types\n",
    "print(\"\\nData Types after Transformation:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for any remaining missing values\n",
    "print(\"\\nRemaining Missing Values across all columns:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e20717d5-ce42-4d84-8b39-4ab415d4aab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Snowflake Succesfully\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "# Step 8.1 —  Connect to Snowflake for Loading\n",
    "\n",
    "# Reconnect to Snowflake for data loading\n",
    "conn = snowflake.connector.connect(\n",
    "    user=os.getenv(\"SNOWFLAKE_USER\"),\n",
    "    password=os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
    "    account=os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
    "    warehouse=os.getenv(\"SNOWFLAKE_WAREHOUSE\"),\n",
    "    database=os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
    "    schema=os.getenv(\"SNOWFLAKE_SCHEMA\")\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "print(\"Connected to Snowflake Succesfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "03ec694b-aaf7-418f-b90b-b7614c2bf025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table 'SALES_DATA_CSV' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Step 8.2 — Create Table in Snowflake\n",
    "\n",
    "# Create Target Table (if not exists)\n",
    "create_table_query = \"\"\"\n",
    "CREATE OR REPLACE TABLE SALES_DATA_CSV (\n",
    "    ROW_ID INT,\n",
    "    ORDER_ID STRING,\n",
    "    ORDER_DATE DATE,\n",
    "    SHIP_DATE DATE,\n",
    "    SHIP_MODE STRING,\n",
    "    CUSTOMER_ID STRING,\n",
    "    CUSTOMER_NAME STRING,\n",
    "    SEGMENT STRING,\n",
    "    COUNTRY STRING,\n",
    "    CITY STRING,\n",
    "    STATE STRING,\n",
    "    POSTAL_CODE INT,\n",
    "    REGION STRING,\n",
    "    PRODUCT_ID STRING,\n",
    "    CATEGORY STRING,\n",
    "    SUB_CATEGORY STRING,\n",
    "    PRODUCT_NAME STRING,\n",
    "    SALES FLOAT,\n",
    "    ORDER_MONTH INT,\n",
    "    DELIVERY_TIME_DAYS INT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(create_table_query)\n",
    "print(\"\\nTable 'SALES_DATA_CSV' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6f948890-40af-4fff-9409-d7ac4f124dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9800 new rows successfully.\n"
     ]
    }
   ],
   "source": [
    "# Step 8.3 — Load Transformed Data into Snowflake (Optimized and Clean)\n",
    "\n",
    "# Define the SQL query for inserting data into Snowflake\n",
    "insert_query = \"\"\"\n",
    "    INSERT INTO SALES_DATA_CSV (\n",
    "        ROW_ID, ORDER_ID, ORDER_DATE, SHIP_DATE, SHIP_MODE, CUSTOMER_ID, CUSTOMER_NAME, \n",
    "        SEGMENT, COUNTRY, CITY, STATE, POSTAL_CODE, REGION, PRODUCT_ID, CATEGORY, \n",
    "        SUB_CATEGORY, PRODUCT_NAME, SALES, ORDER_MONTH, DELIVERY_TIME_DAYS\n",
    "    )\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Filter out existing ROW_IDs from the data to avoid duplicates before loading into Snowflake\n",
    "cur.execute(\"SELECT ROW_ID FROM SALES_DATA_CSV;\")\n",
    "existing_row_ids = set(row[0] for row in cur.fetchall())\n",
    "\n",
    "# Step 2: Prepare data for insertion (only NEW ROW_IDs)\n",
    "data_to_insert = []\n",
    "for index, row in df.iterrows():\n",
    "    if row['Row ID'] not in existing_row_ids:\n",
    "        data_to_insert.append((\n",
    "            row['Row ID'],\n",
    "            row['Order ID'],\n",
    "            row['Order Date'].strftime('%Y-%m-%d') if pd.notnull(row['Order Date']) else None,\n",
    "            row['Ship Date'].strftime('%Y-%m-%d') if pd.notnull(row['Ship Date']) else None,\n",
    "            row['Ship Mode'],\n",
    "            row['Customer ID'],\n",
    "            row['Customer Name'],\n",
    "            row['Segment'],\n",
    "            row['Country'],\n",
    "            row['City'],\n",
    "            row['State'],\n",
    "            row['Postal Code'],\n",
    "            row['Region'],\n",
    "            row['Product ID'],\n",
    "            row['Category'],\n",
    "            row['Sub-Category'],\n",
    "            row['Product Name'],\n",
    "            row['Sales'],\n",
    "            row['Order_Month'],\n",
    "            row['Delivery Time (Days)']\n",
    "        ))\n",
    "\n",
    "# Step 3: Bulk insert new data\n",
    "if data_to_insert:\n",
    "    cur.executemany(insert_query, data_to_insert)\n",
    "    conn.commit()\n",
    "    print(f\"Loaded {len(data_to_insert)} new rows successfully.\")\n",
    "else:\n",
    "    print(\"No new orders to Load. Database is already up-to-date.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "37c9b748-bcc9-4c24-aadc-22f35d02f3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row counts match: 9800 rows loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Final Data Integrity Check\n",
    "# Step 9.1: Compare row counts between the source and the target table\n",
    "# Row count in the CSV\n",
    "source_row_count = len(df)\n",
    "\n",
    "# Row count in Snowflake (target table)\n",
    "cur.execute(\"SELECT COUNT(*) FROM SALES_DATA_CSV;\")\n",
    "snowflake_row_count = cur.fetchone()[0]\n",
    "\n",
    "# Check if the row counts match\n",
    "if source_row_count == snowflake_row_count:\n",
    "    print(f\"Row counts match: {source_row_count} rows loaded successfully.\")\n",
    "else:\n",
    "    print(f\"Warning: Row count mismatch. Source: {source_row_count}, Snowflake: {snowflake_row_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d9f27871-f95b-4ad5-88eb-b6539b8ed283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-Load Check: No duplicate ROW_IDs found. Data is consistent.\n"
     ]
    }
   ],
   "source": [
    "# Step 9.2 — Check for Duplicates (ROW_ID Check)\n",
    "\n",
    "# Query to check for duplicate ROW_IDs in the Snowflake table\n",
    "cur.execute(\"\"\"\n",
    "    SELECT ROW_ID, COUNT(*) \n",
    "    FROM SALES_DATA_CSV \n",
    "    GROUP BY ROW_ID \n",
    "    HAVING COUNT(*) > 1;\n",
    "\"\"\")\n",
    "\n",
    "duplicates = cur.fetchall()\n",
    "\n",
    "if duplicates:\n",
    "    print(f\"Post-Load Check: Found {len(duplicates)} duplicate ROW_ID(s).\")\n",
    "else:\n",
    "    print(\"Post-Load Check: No duplicate ROW_IDs found. Data is consistent.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a58a6011-c1b0-405e-8866-ccbff4c49c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Check: No NULL values found in critical columns.\n"
     ]
    }
   ],
   "source": [
    "# Step 9.3 — Data Quality Check (Look for Nulls or Invalid Data)\n",
    "\n",
    "# Query to check for NULL values in critical columns\n",
    "cur.execute(\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM SALES_DATA_CSV\n",
    "    WHERE ROW_ID IS NULL OR SALES IS NULL OR CUSTOMER_ID IS NULL;\n",
    "\"\"\")\n",
    "\n",
    "null_count = cur.fetchone()[0]\n",
    "\n",
    "if null_count > 0:\n",
    "    print(f\"Data Quality Check: Found {null_count} rows with NULL values in critical columns.\")\n",
    "else:\n",
    "    print(\"Data Quality Check: No NULL values found in critical columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5b5d5efe-7be1-42ad-bb07-6abebcf03129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation: Data integrity confirmed. SALES sum matches between CSV and Snowflake.\n"
     ]
    }
   ],
   "source": [
    "# Step 9.4 — Final Validation (Data Integrity)\n",
    "\n",
    "# Query to check if the sum of SALES in the CSV matches the sum in the Snowflake table\n",
    "cur.execute(\"SELECT SUM(SALES) FROM SALES_DATA_CSV;\")\n",
    "snowflake_sales_sum = cur.fetchone()[0]\n",
    "\n",
    "# Get the sum of SALES from the CSV (assuming 'df' is the DataFrame containing your CSV data)\n",
    "csv_sales_sum = df['Sales'].sum()\n",
    "\n",
    "# Round both sums to 4 decimal places for a more accurate comparison\n",
    "snowflake_sales_sum_rounded = round(snowflake_sales_sum, 4)\n",
    "csv_sales_sum_rounded = round(csv_sales_sum, 4)\n",
    "\n",
    "if snowflake_sales_sum_rounded == csv_sales_sum_rounded:\n",
    "    print(\"Final Validation: Data integrity confirmed. SALES sum matches between CSV and Snowflake.\")\n",
    "else:\n",
    "    print(f\"Final Validation: WARNING! SALES sum mismatch. CSV: {csv_sales_sum_rounded}, Snowflake: {snowflake_sales_sum_rounded}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
